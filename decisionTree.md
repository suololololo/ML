# 决策树
what?<br>
决策树是一个分类与回归模型，基于特征对实例进行分类，对特征空间和类空间进行划分。
<br>
用决策树分类，从根节点开始，对实例的某一特征进行测试，根据测试结果，将实例划分到其子节点，此时，每一个节点对应特征的一个取值，递归上述过程，直到到达叶子节点，最好将实例分配到叶子节点的类中。

<h2>特征选择</h2>
决策树生成过程需要将实例的某个特征进行测试划分，那么选择哪个特征呢?<br>

**信息熵** <br>
信息熵定义为信息的混乱程度，即越大，信息越混乱。
随机变量X的熵定义为
$
H(X) = -\sum_{i=1}^n p_i log p_i \tag{1}
$
其中,随机变量X有n个取值
$
P(X = x_i) = p_i \tag{2}
$
从1式子中可以看到X的熵与X无关，只与X的概率分布有关。因此X的熵也可以记为$H(p)$ <br>
条件熵$H(Y|X)$ 表示在X确定的情况下，随机变量Y的不确定性,定义为
$
H(Y|X) = \sum_{i=1}^n p_i H(Y| X = x_i) \tag{3}
$
表示在x确定的情况下Y的条件概率熵对X的数学期望
其中
$
P(X = x_i) = p_i  \quad i = 1,2,...,n \tag{4}
$
熵和条件熵可由数据估计得到，称为经验熵和条件经验熵<br>

**信息增益**<br>
特征A对数据集D的信息增益定义为
$
g(D,A) = H(D) - H(D|A) \tag{5}
$
即利用特征A对数据集D进行划分后，熵的减少程度。<br>

**信息增益算法** <br>
设训练数据集为D，$|D|$ ,表示样本个数，有K个类别$C_K,k=1,2,...,K$,$|C_K|$表示属于类$C_K$的样本大小。设特征A有n个取值，${a_1,a_2,...,a_n}$,根据A的取值将D划分为$D_1,D_2,...,D_n$,子集$D_i$中属于类 $C_K$的记为$D_{ik}$ <br>
计算特征A对训练数据集D信息增益
$
H(D) = -\sum_{i=1}^K p_i logp_i = -\sum_{i=1}^K {|D_i| \over |D|} log {|D_i| \over |D|} \tag{6}
$
计算条件熵
$
H(D,A)=\sum_{i=1}^n p_iH(D|A=a_i) = \sum_{i=1}^n {|D_i| \over |D|}H(D|A=a_i) \\=  \sum_{i=1}^n {|D_i| \over |D|} -\sum_{k=1}^K P(D=c_k|A =a_i) logP(D=c_k|A =a_i) \\= -\sum_{i=1}^n {|D_i| \over |D|} \sum_{k=1}^K{|D_{ik}| \over |D_i|}log{|D_{ik}| \over |D_i|} \tag{7}
$
计算信息增益
$
g(D,A) = H(D) - H(D,A) \tag{8}
$

根据上面公式6，7，8可计算任意特征对数据集信息增益，选取信息增益最大的特征对数据集进行划分


<h2>决策树的生成</h2>
决策树可由不同算法生成ID3,C4.5,CART等等<br>
<br>

**ID3算法**<br>
ID3算法采用信息增益准则选择特征，即在每个节点上应用信息增益算法，选择信息增益最大的特征，切分，递归构建决策树。<br>
<br>

**C4.5算法** <br>
c4.5与ID3算法类似，只不过采用了信息增益比来进行特征选择,信息增益比的定义为信息增益与训练数据集D关于特征A的信息熵的比

$
g_R(D,A) = {g(D,A) \over H_A(D)} \tag{9}
$

**为什么采用信息增益比？**<br>
因为以信息增益划分数据集的特征时，存在偏向于选择取值较多的特征的问题。信息增益比可以校正这一问题


**基尼系数**<br>
设分类问题中，有K个类，样本点属于第K类的概率为$p_k$

$
Gini(p) = \sum_{k=1}^{K}p_k(1-p_k) \tag{10}
$
如果数据集D可以根据某一特征A划分为$D_1$和$D_2$两部分，则在特征A的条件下，数据集D的基尼系数为

$
Gini(D,A) = {|D_1| \over |D|}Gini(D_1) + {|D_2| \over |D|} Gini(D_2) \tag{11}
$

基尼系数表示集合D的不确定性，基尼系数越大，不确定性越高


**决策树剪枝**<br>
设树T有叶子节点$|T|$个,t是树T的叶子节点，该叶子节点上有$N_t$个样本点，其中k类的样本点有$N_{tk}$个,$H_t(T)$是叶子节点t上的经验熵
定义损失函数,

$
C_a(T) = \sum_{t=1}^{|T|} N_tH_t(T) + a|T| \tag{12}
$
其中第一项代表模型训练误差，第二项为模型复杂度